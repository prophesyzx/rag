{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96703ef3",
   "metadata": {},
   "source": [
    "## 1. 选择模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aee4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_PROJECT_ID\"] = \"project-rag-1.0.0\"\n",
    "os.environ[\"LANGSMITH_PROJECT_NAME\"] = \"rag-sample\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "\n",
    "from langchain_deepseek.chat_models import ChatDeepSeek  # 导入 DeepSeek 的聊天模型\n",
    "from langchain_huggingface import HuggingFaceEmbeddings # 导入 HuggingFace 的嵌入模型\n",
    "from langchain.chains import RetrievalQA # 导入检索问答链\n",
    "from langchain.prompts import PromptTemplate # 导入提示模板\n",
    "from langchain.chains import LLMChain # 导入 LLM 链\n",
    "from langchain.memory import ConversationBufferMemory # 导入对话缓冲区内存\n",
    "from langchain_chroma import Chroma # 导入 Chroma 向量存储"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c62c92",
   "metadata": {},
   "source": [
    "### 1. 聊天模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854b0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 DeepSeek 聊天模型实例\n",
    "deepseek_api_key = \"sk-fffbb9b8a78d436a91a4780356b67a93\"\n",
    "# 选择deepseek-V3模型\n",
    "llm = ChatDeepSeek(model=\"deepseek-chat\", api_key = deepseek_api_key, temperature=0, base_url='https://api.deepseek.com')\n",
    "# 选择deepseek-R1模型\n",
    "# llm = ChatDeepSeek(model=\"deepseek-reason\", api_key = deepseek_api_key, temperature=0, base_url='https://api.deepseek.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f01b02",
   "metadata": {},
   "source": [
    "### 2. 嵌入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46246b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zx\\AppData\\Local\\Temp\\ipykernel_36456\\1769943512.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  bge_zh_embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 初始化模型\n",
    "model_kwargs = {'device': 'cuda'} # 使用 GPU 进行推理\n",
    "encode_kwargs = {'normalize_embeddings': True}  # 是否归一化\n",
    "\n",
    "# 创建 HuggingFace 嵌入模型实例\n",
    "# BGE系列的经典模型\n",
    "bge_zh_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-large-zh-v1.5\",\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddde09d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从lier007/xiaobu-embedding-v2、dunzhang/stella-large-zh-v3-1792d 和 BAAI/bge-multilingual-gemma2 中蒸馏得到\n",
    "ri_zh_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"richinfoai/ritrieve_zh_v1\",\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fced5739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGE系列的新模型，参数更大，但速度更慢\n",
    "bge_m3_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d887c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也是中文的embedding模型\n",
    "m3e_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"moka-ai/m3e-base\",\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d509ac9",
   "metadata": {},
   "source": [
    "## 2. 构建索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc7690",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df2dbba",
   "metadata": {},
   "source": [
    "#### JSONL文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c953af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "\n",
    "file_path = \"database/json/all_data.jsonl\" # 数据文件路径\n",
    "\n",
    "# 定义元数据函数\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    metadata[\"title\"] = record.get(\"Title\")\n",
    "    metadata[\"date\"] = record.get(\"Date\")\n",
    "    metadata[\"viewcount\"] = record.get(\"ViewCount\")\n",
    "    metadata['source'] = file_path\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "# 加载数据\n",
    "json_loader = JSONLoader(\n",
    "    file_path=file_path,\n",
    "    jq_schema='.[]',\n",
    "    content_key=\"Content\",\n",
    "    metadata_func=metadata_func,\n",
    "    text_content=True,\n",
    "    json_lines=True,\n",
    "    )\n",
    "\n",
    "json_data = json_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ebc49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456d06c",
   "metadata": {},
   "source": [
    "#### PDF文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873c0b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# 加载 PDF 文件\n",
    "pdf_loader = PyPDFDirectoryLoader(\"database/pdf\")\n",
    "pdf_data = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9534c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d851ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = json_data + pdf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703bfd5",
   "metadata": {},
   "source": [
    "## 切分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "107b0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 创建文本分割器，设置分割参数\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    add_start_index=True,\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \"\\u200b\",  # Zero-width space\n",
    "        \"\\uff0c\",  # Fullwidth comma\n",
    "        \"\\u3001\",  # Ideographic comma\n",
    "        \"\\uff0e\",  # Fullwidth full stop\n",
    "        \"\\u3002\",  # Ideographic full stop\n",
    "        \"\",\n",
    "    ],\n",
    ")\n",
    "# 将数据分割成小块\n",
    "data_splits = text_splitter.split_documents(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd45680",
   "metadata": {},
   "source": [
    "## 存储数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2dacd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb_ri = Chroma.from_documents(\n",
    "    documents=data_splits, \n",
    "    embedding=ri_zh_embeddings,\n",
    "    collection_name=\"ri_collection\",\n",
    "    persist_directory=\"ri_embedding\",\n",
    ")  # 创建 Chroma 向量存储实例"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05396805",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "vectordb_bge = Chroma(\n",
    "    collection_name=\"bge_collection\",\n",
    "    embedding_function=bge_zh_embeddings,\n",
    "    persist_directory=\"bge_embedding\",  # Where to save data locally, remove if not necessary\n",
    ").from_documents(documents=data_splits, embedding=bge_zh_embeddings)  # 创建 Chroma 向量存储实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d5811c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb_bge = Chroma.from_documents(\n",
    "    documents=data_splits, \n",
    "    embedding=bge_zh_embeddings,\n",
    "    collection_name=\"bge_collection\",\n",
    "    persist_directory=\"bge_embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c7f71",
   "metadata": {},
   "source": [
    "## 3. 检索增强"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315cf58e",
   "metadata": {},
   "source": [
    "### EnsembleRetriever（合并多个检索器）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ed1645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_transformers import EmbeddingsClusteringFilter\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain.retrievers import MergerRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbb9a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_bge = vectordb_bge.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 5}\n",
    ")\n",
    "retriever_ri = vectordb_ri.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "lotr = MergerRetriever(retrievers=[retriever_bge, retriever_ri])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe0bd6b",
   "metadata": {},
   "source": [
    "### 上下文压缩 + 重排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "067d4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_transformers import LongContextReorder\n",
    "\n",
    "# Reorder the documents:\n",
    "# Less relevant document will be at the middle of the list and more\n",
    "# relevant elements at beginning / end.\n",
    "reordering = LongContextReorder()\n",
    "filter_by_retriever = EmbeddingsRedundantFilter(embeddings=bge_m3_embeddings)\n",
    "\n",
    "pipeline = DocumentCompressorPipeline(transformers=[filter_by_retriever, reordering])\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline, base_retriever=lotr\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ce9f3",
   "metadata": {},
   "source": [
    "### MultiQueryRetriever（多角度问题召回器）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3533f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "# Output parser will split the LLM result into a list of queries\n",
    "class LineListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Output parser for a list of lines.\"\"\"\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        lines = text.strip().split(\"\\n\")\n",
    "        return list(filter(None, lines))  # Remove empty lines\n",
    "\n",
    "def get_unique_ordered_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"Get unique documents in the order they appear.\"\"\"\n",
    "    seen = set()\n",
    "    unique_docs = []\n",
    "    for doc in docs:\n",
    "        if str(doc.page_content) not in seen:\n",
    "            seen.add(str(doc.page_content))\n",
    "            unique_docs.append(doc)\n",
    "    return unique_docs\n",
    "\n",
    "def multi_retriever(question: str) -> List[Document]:\n",
    "    \"\"\"Create a retriever that generates multiple queries.\"\"\"\n",
    "    # Prompt template for generating multiple queries\n",
    "    QUERY_PROMPT = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"\"\"你的任务是生成三个不同的问题版本，以便从向量数据库中检索相关文档。通过从多个角度重新表述用户的问题，你的目标是帮助用户克服基于距离的相似性搜索的一些局限性。请将这些替代问题用换行分隔，不需要用数字或符号进行编号。首行生成原始问题，同样用换行分隔。原始问题：{question}\"\"\",\n",
    "    )\n",
    "    output_parser = LineListOutputParser()\n",
    "    llm = ChatDeepSeek(model=\"deepseek-chat\", api_key = deepseek_api_key, temperature=0.0, base_url='https://api.deepseek.com')\n",
    "    llm_chain = QUERY_PROMPT | llm | output_parser\n",
    "    retriever = MultiQueryRetriever(\n",
    "        retriever=compression_retriever, \n",
    "        llm_chain=llm_chain, \n",
    "        parser_key=\"lines\"\n",
    "    )  # \"lines\" is the key (attribute name) of the parsed output\n",
    "    docs = retriever.invoke(question)\n",
    "    unique_docs = get_unique_ordered_docs(docs)\n",
    "    \n",
    "    return unique_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8226a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"京剧旦角主要分为哪几个流派？\"\n",
    "# unique_docs = multi_retriever(question)\n",
    "# Print the unique documents\n",
    "# print(f\"Number of unique documents: {len(unique_docs)}\\n\")\n",
    "# print(unique_docs[0].page_content)\n",
    "#print(\"=\" * 50)\n",
    "#print(unique_docs[-1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c1700",
   "metadata": {},
   "source": [
    "### 自查询-过滤元数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49dbca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"viewcount\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"date\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42356db",
   "metadata": {},
   "source": [
    "## 4. 生成回答"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc002b",
   "metadata": {},
   "source": [
    "### 提示词模版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01dafb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"使用以下的上下文片段回答最后的问题。\n",
    "如果你不知道答案，只需说你不知道，不要编造答案。\n",
    "答案最多使用三句话，并尽量保持简洁。在回答的最后总是说\"谢谢提问！\"\n",
    "\n",
    "{context}\n",
    "\n",
    "问题：{question}\n",
    "\n",
    "回答：\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f6a2a0",
   "metadata": {},
   "source": [
    "### LangGraph状态图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bb7a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = multi_retriever(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = rag_prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    llm = ChatDeepSeek(model=\"deepseek-chat\", api_key = deepseek_api_key, base_url='https://api.deepseek.com')\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a655a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "workflow = StateGraph(State).add_sequence([retrieve, generate])\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a7446d",
   "metadata": {},
   "source": [
    "### 主程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a8bb067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['京剧是如何从地方戏曲逐步融合演变成为国剧的？其关键历史节点和艺术融合过程是怎样的？', '京剧在不同朝代（如清代、民国、新中国）经历了哪些标志性变革？这些变革如何影响了其表演体系和艺术特征？', '从徽班进京到四大名旦时期，京剧艺术形式发生了哪些根本性转变？请分析唱腔、脸谱、行当等核心元素的历史流变及其文化内涵。']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "京剧起源于清初流行于江南地区的徽班，1790年四大徽班进京为乾隆贺寿后留京发展，逐渐融合徽戏、秦腔、汉调等声腔，并吸收昆曲、京腔元素，于道光年间（1840-1860年）形成完整剧种。其艺术特点包括\"唱念做打\"四功、西皮二黄腔调及写意化舞台表现，代表人物有程长庚、谭鑫培、梅兰芳等，重要改革包括民国时期的\"时装新戏\"和新中国成立后的现代戏创作。谢谢提问！\n"
     ]
    }
   ],
   "source": [
    "# question = \"京剧旦角主要分为哪几个流派？\"\n",
    "\n",
    "result = app.invoke({\"question\": \"请详细阐述京剧的起源背景、形成过程及其在不同历史时期的发展演变，包括主要艺术特点、代表性人物和重要改革事件。\"})\n",
    "\n",
    "# print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: \\n{result[\"answer\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
