{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96703ef3",
   "metadata": {},
   "source": [
    "## 1. 选择模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aee4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_PROJECT_ID\"] = \"project-rag-1.0.0\"\n",
    "os.environ[\"LANGSMITH_PROJECT_NAME\"] = \"rag-sample\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "\n",
    "from langchain_deepseek.chat_models import ChatDeepSeek  # 导入 DeepSeek 的聊天模型\n",
    "from langchain_huggingface import HuggingFaceEmbeddings # 导入 HuggingFace 的嵌入模型\n",
    "from langchain.chains import RetrievalQA # 导入检索问答链\n",
    "from langchain.prompts import PromptTemplate # 导入提示模板\n",
    "from langchain.chains import LLMChain # 导入 LLM 链\n",
    "from langchain.memory import ConversationBufferMemory # 导入对话缓冲区内存\n",
    "from langchain_chroma import Chroma # 导入 Chroma 向量存储"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c62c92",
   "metadata": {},
   "source": [
    "### 1. 聊天模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "854b0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 DeepSeek 聊天模型实例\n",
    "deepseek_api_key = \"sk-fffbb9b8a78d436a91a4780356b67a93\"\n",
    "# 选择deepseek-V3模型\n",
    "llm = ChatDeepSeek(model=\"deepseek-chat\", api_key = deepseek_api_key, temperature=0, base_url='https://api.deepseek.com')\n",
    "# 选择deepseek-R1模型\n",
    "# llm = ChatDeepSeek(model=\"deepseek-reason\", api_key = deepseek_api_key, temperature=0, base_url='https://api.deepseek.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f01b02",
   "metadata": {},
   "source": [
    "### 2. 嵌入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46246b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 初始化模型\n",
    "model_kwargs = {'device': 'cuda'} # 使用 GPU 进行推理\n",
    "encode_kwargs = {'normalize_embeddings': True}  # 是否归一化\n",
    "\n",
    "# 创建 HuggingFace 嵌入模型实例\n",
    "# 这里使用了 BAAI 的 BGE 模型，可以根据需要选择其他模型\n",
    "bge_zh_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-large-zh-v1.5\",\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced5739",
   "metadata": {},
   "outputs": [],
   "source": [
    "bge_m3_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d887c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cad4d0b130444da5e9e5fa2a516182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/204 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949ceebc93a84c83a478ed835a7f2be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931236505c764400aa57acaeb27fcdf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f747b69e9374fe2bab74a29e241235b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"aspire/acge_text_embedding\",\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d509ac9",
   "metadata": {},
   "source": [
    "## 2. 构建索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc7690",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df2dbba",
   "metadata": {},
   "source": [
    "#### JSONL文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "\n",
    "file_path = \"database/json/sample_data.jsonl\" # 数据文件路径\n",
    "\n",
    "# 定义元数据函数\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    metadata[\"title\"] = record.get(\"Title\")\n",
    "    metadata[\"date\"] = record.get(\"Date\")\n",
    "    metadata[\"viewcount\"] = record.get(\"ViewCount\")\n",
    "    metadata['source'] = file_path\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "# 加载数据\n",
    "json_loader = JSONLoader(\n",
    "    file_path=file_path,\n",
    "    jq_schema='.[]',\n",
    "    content_key=\"Content\",\n",
    "    metadata_func=metadata_func,\n",
    "    text_content=True,\n",
    "    json_lines=True,\n",
    "    )\n",
    "\n",
    "json_data = json_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456d06c",
   "metadata": {},
   "source": [
    "#### PDF文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c0b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# 加载 PDF 文件\n",
    "pdf_loader = PyPDFDirectoryLoader(\"database/pdf\")\n",
    "pdf_data = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d851ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = json_data + pdf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703bfd5",
   "metadata": {},
   "source": [
    "## 切分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 创建文本分割器，设置分割参数\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    add_start_index=True,\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \"\\u200b\",  # Zero-width space\n",
    "        \"\\uff0c\",  # Fullwidth comma\n",
    "        \"\\u3001\",  # Ideographic comma\n",
    "        \"\\uff0e\",  # Fullwidth full stop\n",
    "        \"\\u3002\",  # Ideographic full stop\n",
    "        \"\",\n",
    "    ],\n",
    ")\n",
    "# 将数据分割成小块\n",
    "data_splits = text_splitter.split_documents(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd45680",
   "metadata": {},
   "source": [
    "## 存储数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e4796a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bge_zh_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m vectordb_m3 \u001b[38;5;241m=\u001b[39m Chroma(\n\u001b[0;32m      2\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_collection_1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     embedding_function\u001b[38;5;241m=\u001b[39mbge_m3_embeddings,\n\u001b[0;32m      4\u001b[0m     persist_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./sample_chroma_1\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Where to save data locally, remove if not necessary\u001b[39;00m\n\u001b[0;32m      5\u001b[0m )\u001b[38;5;241m.\u001b[39mfrom_documents(documents\u001b[38;5;241m=\u001b[39mdata_splits, embedding\u001b[38;5;241m=\u001b[39mbge_m3_embeddings)  \u001b[38;5;66;03m# 创建 Chroma 向量存储实例\u001b[39;00m\n\u001b[0;32m      7\u001b[0m vectordb_zh \u001b[38;5;241m=\u001b[39m Chroma(\n\u001b[0;32m      8\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_collection_2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m----> 9\u001b[0m     embedding_function\u001b[38;5;241m=\u001b[39m\u001b[43mbge_zh_embeddings\u001b[49m,\n\u001b[0;32m     10\u001b[0m     persist_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./sample_chroma_2\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Where to save data locally, remove if not necessary\u001b[39;00m\n\u001b[0;32m     11\u001b[0m )\u001b[38;5;241m.\u001b[39mfrom_documents(documents\u001b[38;5;241m=\u001b[39mdata_splits, embedding\u001b[38;5;241m=\u001b[39mbge_zh_embeddings)  \u001b[38;5;66;03m# 创建 Chroma 向量存储实例\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bge_zh_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "vectordb_m3 = Chroma(\n",
    "    collection_name=\"sample_collection_1\",\n",
    "    embedding_function=bge_m3_embeddings,\n",
    "    persist_directory=\"./sample_chroma_1\",  # Where to save data locally, remove if not necessary\n",
    ").from_documents(documents=data_splits, embedding=bge_m3_embeddings)  # 创建 Chroma 向量存储实例\n",
    "\n",
    "vectordb_zh = Chroma(\n",
    "    collection_name=\"sample_collection_2\",\n",
    "    embedding_function=bge_zh_embeddings,\n",
    "    persist_directory=\"./sample_chroma_2\",  # Where to save data locally, remove if not necessary\n",
    ").from_documents(documents=data_splits, embedding=bge_zh_embeddings)  # 创建 Chroma 向量存储实例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c7f71",
   "metadata": {},
   "source": [
    "## 3. 检索增强"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315cf58e",
   "metadata": {},
   "source": [
    "### EnsembleRetriever（合并多个检索器）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed1645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_transformers import EmbeddingsClusteringFilter\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain.retrievers import MergerRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb9a222",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectordb_zh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m retriever_zh \u001b[38;5;241m=\u001b[39m \u001b[43mvectordb_zh\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(\n\u001b[0;32m      2\u001b[0m     search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m, search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m retriever_m3 \u001b[38;5;241m=\u001b[39m vectordb_m3\u001b[38;5;241m.\u001b[39mas_retriever(\n\u001b[0;32m      5\u001b[0m     search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmr\u001b[39m\u001b[38;5;124m\"\u001b[39m, search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m lotr \u001b[38;5;241m=\u001b[39m MergerRetriever(retrievers\u001b[38;5;241m=\u001b[39m[retriever_zh, retriever_m3])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectordb_zh' is not defined"
     ]
    }
   ],
   "source": [
    "retriever_zh = vectordb_zh.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 5, \"include_metadata\": True}\n",
    ")\n",
    "retriever_m3 = vectordb_m3.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 5, \"include_metadata\": True}\n",
    ")\n",
    "\n",
    "lotr = MergerRetriever(retrievers=[retriever_zh, retriever_m3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe0bd6b",
   "metadata": {},
   "source": [
    "### 上下文压缩 + 重排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d4309",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lotr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;241m=\u001b[39m EmbeddingsRedundantFilter(embeddings\u001b[38;5;241m=\u001b[39mfilter_embeddings)\n\u001b[0;32m     10\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m DocumentCompressorPipeline(transformers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mfilter\u001b[39m, reordering])\n\u001b[0;32m     11\u001b[0m compression_retriever \u001b[38;5;241m=\u001b[39m ContextualCompressionRetriever(\n\u001b[1;32m---> 12\u001b[0m     base_compressor\u001b[38;5;241m=\u001b[39mpipeline, base_retriever\u001b[38;5;241m=\u001b[39m\u001b[43mlotr\u001b[49m\n\u001b[0;32m     13\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lotr' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_transformers import LongContextReorder\n",
    "\n",
    "# Reorder the documents:\n",
    "# Less relevant document will be at the middle of the list and more\n",
    "# relevant elements at beginning / end.\n",
    "reordering = LongContextReorder()\n",
    "\n",
    "filter = EmbeddingsRedundantFilter(embeddings=filter_embeddings)\n",
    "#filter_ordered_by_retriever = EmbeddingsClusteringFilter(\n",
    "#    embeddings=filter_embeddings,\n",
    "#    num_clusters=10,\n",
    "#    num_closest=1,\n",
    "#    sorted=True,\n",
    "#)\n",
    "\n",
    "pipeline = DocumentCompressorPipeline(transformers=[filter, reordering])\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline, base_retriever=lotr\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ce9f3",
   "metadata": {},
   "source": [
    "### MultiQueryRetriever（多角度问题召回器）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3533f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. 京剧中的旦角有哪些著名的表演流派？  ', '2. 京剧旦角的表演风格主要分为哪几类？  ', '3. 京剧旦角的艺术流派有哪些代表性人物？  ', '4. 京剧旦角的流派划分及其特点是什么？  ', '5. 京剧旦角在表演艺术上有哪些不同的派别？']\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import List\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "# Output parser will split the LLM result into a list of queries\n",
    "class LineListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Output parser for a list of lines.\"\"\"\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        lines = text.strip().split(\"\\n\")\n",
    "        return list(filter(None, lines))  # Remove empty lines\n",
    "    \n",
    "\n",
    "def my_retriever(question: str) -> List[Document]:\n",
    "    \"\"\"Create a retriever that generates multiple queries.\"\"\"\n",
    "    # Prompt template for generating multiple queries\n",
    "    QUERY_PROMPT = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"\"\"你的任务是生成五个不同的问题版本，以便从向量数据库中检索相关文档。通过从多个角度重新表述用户的问题，你的目标是帮助用户克服基于距离的相似性搜索的一些局限性。请将这些替代问题用换行分隔。原始问题：{question}\"\"\",\n",
    "    )\n",
    "    output_parser = LineListOutputParser()\n",
    "    llm = ChatDeepSeek(model=\"deepseek-chat\", api_key = deepseek_api_key, temperature=0, base_url='https://api.deepseek.com')\n",
    "    llm_chain = QUERY_PROMPT | llm | output_parser\n",
    "    retriever = MultiQueryRetriever(\n",
    "        retriever=compression_retriever, llm_chain=llm_chain, parser_key=\"lines\"\n",
    "    )  # \"lines\" is the key (attribute name) of the parsed output\n",
    "    docs = retriever.invoke(question)\n",
    "    reordering = LongContextReorder()\n",
    "    reordered_docs = reordering.transform_documents(docs)\n",
    "    \n",
    "    return reordered_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226a45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique documents: 15\n",
      "尚派京剧\n",
      "京剧，又称平剧、京戏等，中国国粹之一，是中国影响最大的戏曲剧种，分布地以北京为中心，遍及全国各地。京剧流派主要是指演员的表演艺术风格和艺术特点，并且这种风格特点得到师承和传播。\n",
      "一个剧种中出现不同的流派是艺术发展的必然产物，多种流派的形成是艺术昌盛的反映。京剧旦角主要分为四大流派：梅派、程派、荀派、尚派。\n",
      "尚派艺术的创始人是尚小云。尚派行腔吐字清楚，以嗓音清亮激越、旋律跌宕缭绕的传统，以板头的变化运用，打破唱腔的固定节奏，展示唱腔的丰富内涵；又以斩钉截铁的断和错综有力的顿挫，使唱腔错落有致，往往在平易简约、坚实整齐中呈现峭险之处，显得力透纸背。\n",
      "本期线上U课由佳木斯市群众艺术馆邀请佳木斯市京剧团知名艺术家、国家一级演员吴玲玲，为大家讲解尚派京剧的基本知识、念白、唱段，并进行教学示范。\n",
      "扫描二维码观看精彩课程\n",
      "课程内容\n",
      "第一节 走进京剧\n",
      "京剧流播全国，影响甚广，有“国剧”之称。京剧的角色分为生、旦、净、丑、杂、武、流等行当，后三行已不再立专行。各行当都有一套表演程式，唱念做打的技艺各具特色。\n",
      "第二节 青衣与花旦的区别\n",
      "==================================================\n",
      "i\n",
      "国家公共文化数字支撑平台\n",
      "数字资源标准规范\n",
      "第四部分\n",
      "数字资源元数据标准规范、交换标准规范\n",
      "及著录规则\n",
      "委托方：文化部全国公共文化发展中心\n",
      "研制方：北京大学\n",
      "201\n",
      "5\n",
      "年\n",
      "4\n",
      "月\n"
     ]
    }
   ],
   "source": [
    "# Print the unique documents\n",
    "#print(f\"Number of unique documents: {len(unique_docs)}\")\n",
    "#print(unique_docs[0].page_content)\n",
    "#print(\"=\" * 50)\n",
    "#print(unique_docs[-1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c1700",
   "metadata": {},
   "source": [
    "### 自查询-过滤元数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"viewcount\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"date\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42356db",
   "metadata": {},
   "source": [
    "## 4. 生成回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dafb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"使用以下的上下文片段回答最后的问题。\n",
    "如果你不知道答案，只需说你不知道，不要编造答案。\n",
    "答案最多使用三句话，并尽量保持简洁。在回答的最后总是说“谢谢提问！”\n",
    "\n",
    "{context}\n",
    "\n",
    "问题：{question}\n",
    "\n",
    "回答：\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb7a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = my_retriever(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = rag_prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a655a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "workflow = StateGraph(State).add_sequence([retrieve, generate])\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8bb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"京剧旦角主要分为哪几个流派？\"\n",
    "\n",
    "result = app.invoke({\"question\": question})\n",
    "\n",
    "# print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: \\n{result[\"answer\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
