{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7007a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3b472",
   "metadata": {},
   "source": [
    "## 0. 加载模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5eff6",
   "metadata": {},
   "source": [
    "### 1. chat模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000cdd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek.chat_models import ChatDeepSeek  # 导入 DeepSeek 的聊天模型\n",
    "\n",
    "deepseek_api_key = \"sk-fffbb9b8a78d436a91a4780356b67a93\"\n",
    "\n",
    "llm = ChatDeepSeek(model=\"deepseek-chat\", api_key = deepseek_api_key)\n",
    "\n",
    "# response = llm.invoke([\"你是一名咨询助理，请为华为写一个简介\"])\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87640cc7",
   "metadata": {},
   "source": [
    "### 2. embedding模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "962ed56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a6327d",
   "metadata": {},
   "source": [
    "### 3. 向量存储库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce1ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2093adb",
   "metadata": {},
   "source": [
    "## 2.实施"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e22c85a",
   "metadata": {},
   "source": [
    "## 1. Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1875363f",
   "metadata": {},
   "source": [
    "#### Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4748323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43130\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e49c681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078aaeb7",
   "metadata": {},
   "source": [
    "#### Splitting documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9132c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 66 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7640e860",
   "metadata": {},
   "source": [
    "#### Storing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63355148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9bb0822b-9ab3-48a0-969b-4f84d259f657', '59000042-856c-4a08-b78d-eed13cb48fa4', 'eaf6ec9d-74d4-435f-b955-e1f4f8bd9d52']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f9671",
   "metadata": {},
   "source": [
    "## 2. Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3030974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d6568",
   "metadata": {},
   "source": [
    "### state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9df73a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc75c97",
   "metadata": {},
   "source": [
    "### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4142f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a00e10",
   "metadata": {},
   "source": [
    "### Control flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eb2d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eb221df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bec154",
   "metadata": {},
   "source": [
    "## 3. 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c5a65a",
   "metadata": {},
   "source": [
    "### Invoke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec6d49db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='3f4e4db0-2f42-403b-b5be-955c067425bb', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='9746f326-6b9d-42a9-9298-aa42ac07f69f', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 19372}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\"), Document(id='2281f909-e983-41e8-b597-119d4591fb55', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17413}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), Document(id='70c0e516-4b58-419a-a479-b1dfd3a8d262', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39220}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.')]\n",
      "\n",
      "\n",
      "Answer: Task decomposition is the process of breaking down a complex problem or task into smaller, manageable sub-tasks or steps. It can be performed by an LLM using simple prompts, task-specific instructions, or human inputs. For example, a prompt like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\" can guide the decomposition.  \n",
      "\n",
      "In the context of systems like HuggingGPT, task decomposition is part of the task planning stage, where an LLM parses user requests into structured tasks with attributes like type, ID, dependencies, and arguments. However, challenges remain in long-term planning and adjusting to unexpected errors.\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "\n",
    "print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be058b08",
   "metadata": {},
   "source": [
    "### Stream steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afd1185e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='3f4e4db0-2f42-403b-b5be-955c067425bb', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='9746f326-6b9d-42a9-9298-aa42ac07f69f', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 19372}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\"), Document(id='2281f909-e983-41e8-b597-119d4591fb55', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17413}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), Document(id='70c0e516-4b58-419a-a479-b1dfd3a8d262', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39220}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'Task decomposition is the process of breaking down a complex problem or task into smaller, manageable sub-tasks or steps. It can be performed by an LLM using simple prompts, task-specific instructions, or human input. For example, prompting an LLM with \"Steps for XYZ\" or asking for subgoals helps decompose the task systematically.  \\n\\nIn the context of systems like HuggingGPT, task decomposition occurs during the task planning stage, where the LLM parses user requests into structured tasks with attributes like type, ID, dependencies, and arguments. This enables efficient execution by expert models. However, challenges remain in long-term planning and adapting to unexpected errors.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cd0104",
   "metadata": {},
   "source": [
    "### Stream tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88addca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Task| decomposition| is| the| process| of| breaking| down| a| complex| problem| or| task| into| smaller|,| manageable| subt|asks| or| steps|.| It| can| be| performed| by| an| LL|M| using| simple| prompts|,| task|-specific| instructions|,| or| human| inputs|.| This| method| helps| in| organizing| and| solving| problems| systematically|,| as| seen| in| approaches| like| Tree| of| Thoughts| or| Hug|ging|GPT|.|  \n",
      "\n",
      "|The| process| involves| planning| tasks| (|e|.g|.,| parsing| user| requests| into| subt|asks|),| model| selection|,| and| execution|,| where| expert| models| handle| specific| subt|asks|.| Challenges| include| limited| context| length| and| difficulties| in| long|-term| planning| when| errors| occur|.||"
     ]
    }
   ],
   "source": [
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad28268",
   "metadata": {},
   "source": [
    "### 自定义提示词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43bcb69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a1c16",
   "metadata": {},
   "source": [
    "## 4. Query analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "251fbedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'start_index': 8,\n",
       " 'section': 'beginning'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "all_splits[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df23e9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a8e9ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b29ae37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "859d6de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd09f24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'end'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='1b8edcf8-5ba3-4165-aa9b-d74735e42327', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39220, 'section': 'end'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='55327074-dea8-4f43-8e9f-ad82ad25a694', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 40601, 'section': 'end'}, page_content='Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389'), Document(id='2a416599-edd0-45fc-a0bd-70b6171b16fe', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 30951, 'section': 'end'}, page_content='Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",'), Document(id='20f0c37d-19c0-4f33-a7c7-98430f9574c7', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 41420, 'section': 'end'}, page_content='[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': \"The context does not explicitly mention what the end of the post says about Task Decomposition. I don't know.\"}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What does the end of the post say about Task Decomposition?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47a404b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'beginning'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='a44fe1d8-b86c-484d-b305-ac63752d1ade', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192, 'section': 'beginning'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='077395e6-8b4b-4c86-becb-2342525724ed', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585, 'section': 'beginning'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='324e682e-b824-47e0-88f1-844b72f60111', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 8374, 'section': 'beginning'}, page_content='Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.'), Document(id='e91124d5-7c3c-48a6-8b86-9a66c785f14c', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 8, 'section': 'beginning'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'Task decomposition is the process of breaking down a complex task into smaller, more manageable subgoals or steps. It can be achieved using methods like LLM prompting, task-specific instructions, or human inputs. This technique enhances problem-solving by transforming large tasks into simpler, actionable components.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
